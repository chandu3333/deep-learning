{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "228fff54",
   "metadata": {},
   "source": [
    "## IMPORTING ALL THE MODELS WHICH ARE REQUIRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dcfbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabe325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rd\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4628a",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888098a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arborio = glob.glob(r\"C:\\Users\\HP\\Desktop\\data sets\\Rice_Image_Dataset\\Arborio/*.*\")\n",
    "Basmati = glob.glob(r\"C:\\Users\\HP\\Desktop\\data sets\\Rice_Image_Dataset\\Basmati/*.*\")\n",
    "Ipsala = glob.glob(r\"C:\\Users\\HP\\Desktop\\data sets\\Rice_Image_Dataset\\Ipsala/*.*\")\n",
    "Jasmine = glob.glob(r\"C:\\Users\\HP\\Desktop\\data sets\\Rice_Image_Dataset\\Jasmine/*.*\")\n",
    "Karacadag = glob.glob(r\"C:\\Users\\HP\\Desktop\\data sets\\Rice_Image_Dataset\\Karacadag/*.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43befba",
   "metadata": {},
   "source": [
    "## creating the folders (TRAIN,VALIDATION,TEST)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c01a63b",
   "metadata": {},
   "source": [
    "os.makedirs(r'C:\\Users\\HP\\Desktop\\xx\\train')\n",
    "os.makedirs(r'C:\\Users\\HP\\Desktop\\xx\\test')\n",
    "os.makedirs(r'C:\\Users\\HP\\Desktop\\xx\\validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d436290",
   "metadata": {},
   "source": [
    "## CREATING THE SUB-FOLDERS FOR EACH CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2fc5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\HP\\Desktop\\data sets\\Rice_Image_Dataset\")\n",
    "t = os.listdir()\n",
    "#os.chdir(r'C:\\Users\\HP\\Desktop\\xx')\n",
    "#p=os.listdir()\n",
    "#for i in p:\n",
    " #   os.chdir(r'C:\\Users\\HP\\Desktop\\xx\\\\'+i)\n",
    "  #  for j in t:\n",
    "   #     os.mkdir(r'C:\\Users\\HP\\Desktop\\xx\\\\'+i+'\\\\'+j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2eb977",
   "metadata": {},
   "source": [
    "## splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1337b8",
   "metadata": {},
   "source": [
    "## for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f918a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1=[]\n",
    "for i in t[:5]:\n",
    "    x1=rd.sample(range(len(locals()[i])),k=10000)\n",
    "    z=0\n",
    "    for j in x1:\n",
    "        img=cv2.imread(locals()[i][j])\n",
    "        cv2.imwrite(r\"C:\\Users\\HP\\Desktop\\xx\\train\\\\\"+i+\"\\\\\"+i+\"{}.jpg\".format(z),img)\n",
    "        z=z+1\n",
    "        z1.append(locals()[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a40d0",
   "metadata": {},
   "source": [
    "* to convert strings in to dictionary(key:values)-- locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d48d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "for i in t[:5]:\n",
    "    locals()[i]=list(set(locals()[i]).difference(z1))\n",
    "    print(len(locals()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "259c9b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b06c6f",
   "metadata": {},
   "source": [
    "## FOR TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ccde1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "z2=[]\n",
    "for i in t[:5]:\n",
    "    x1=rd.sample(range(len(locals()[i])),k=2500)\n",
    "    z=0\n",
    "    for j in x1:\n",
    "        img=cv2.imread(locals()[i][j])\n",
    "        cv2.imwrite(r\"C:\\Users\\HP\\Desktop\\xx\\test\\\\\"+i+\"\\\\\"+i+\"{}.jpg\".format(z),img)\n",
    "        z=z+1\n",
    "        z2.append(locals()[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c2d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "for i in t[:5]:\n",
    "    locals()[i]=list(set(locals()[i]).difference(z2))\n",
    "    print(len(locals()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "547b7585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e6bd1",
   "metadata": {},
   "source": [
    "## FOR VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39d9adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z3=[]\n",
    "for i in t[:5]:\n",
    "    x1=rd.sample(range(len(locals()[i])),k=2500)\n",
    "    z=0\n",
    "    for j in x1:\n",
    "        img=cv2.imread(locals()[i][j])\n",
    "        cv2.imwrite(r\"C:\\Users\\HP\\Desktop\\xx\\validation\\\\\"+i+\"\\\\\"+i+\"{}.jpg\".format(z),img)\n",
    "        z=z+1\n",
    "        z3.append(locals()[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e62d4bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in t[:5]:\n",
    "    locals()[i]=list(set(locals()[i]).difference(z3))\n",
    "    print(len(locals()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f33381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c5ba4",
   "metadata": {},
   "source": [
    "## IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d640c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,BatchNormalization,Flatten,Conv2D,AveragePooling2D,MaxPooling2D,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e9175",
   "metadata": {},
   "source": [
    "## CREATING DATA AGUMENTATION, DATA GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5abe05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 5 classes.\n",
      "Found 12500 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(\n",
    "rescale=1./255,\n",
    "rotation_range=20,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2)\n",
    "train_gen = train_data.flow_from_directory(r\"C:\\Users\\HP\\Desktop\\xx\\train\",\n",
    "target_size=(200,200),\n",
    "batch_size=16,\n",
    "class_mode=\"categorical\")\n",
    "\n",
    "val_data = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_gen = val_data.flow_from_directory(r\"C:\\Users\\HP\\Desktop\\xx\\validation\",\n",
    "target_size=(200,200),\n",
    "batch_size=16,\n",
    "class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21863ebe",
   "metadata": {},
   "source": [
    "## CREATING THE ARCHITECHTURE TRANSFER LEARNING CASE:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56aab485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense\n",
    "from keras.callbacks import EarlyStopping as ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad2fb766",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = VGG16(include_top=False,weights='imagenet',input_shape=(200, 200, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f10f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "main.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c54e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(main)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(80,activation=\"relu\"))\n",
    "model.add(Dense(5,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04bac198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 6, 6, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                1474640   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 405       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,189,733\n",
      "Trainable params: 16,189,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef05f337",
   "metadata": {},
   "source": [
    "## COMPILING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "316ae92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen,\n",
    "                   validation_data=val_gen,\n",
    "                   epochs=3,\n",
    "                   steps_per_epoch=50000/16,\n",
    "                   validation_steps=12500/16,\n",
    "                   callbacks=[ES(monitor=\"val_loss\", patience=5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b620bf6",
   "metadata": {},
   "source": [
    "## CREATING THE OUR OWN ARCHITECHTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a8618b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 198, 198, 20)      560       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 99, 99, 20)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 99, 99, 10)        5010      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 49, 49, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 45, 45, 60)        15060     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 121500)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 60)                7290060   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 305       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,310,995\n",
      "Trainable params: 7,310,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(20,(3,3),padding=\"valid\",activation=\"relu\",input_shape=(200,200,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(10,(5,5),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(60,(5,5),activation=\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(60,activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(5,activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1bc5ec",
   "metadata": {},
   "source": [
    "## COMPILING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35980c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83239bd9",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL WITH TRAING DATA GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d034604",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4608\\742987723.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_gen,steps_per_epoch=50000//16,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3125/3125 [==============================] - 15882s 5s/step - loss: 0.2491 - accuracy: 0.9008 - val_loss: 3.0103 - val_accuracy: 0.6522\n",
      "Epoch 2/3\n",
      "3125/3125 [==============================] - 43467s 14s/step - loss: 0.0652 - accuracy: 0.9774 - val_loss: 1.0169 - val_accuracy: 0.8333\n",
      "Epoch 3/3\n",
      "3125/3125 [==============================] - 2764s 884ms/step - loss: 0.0546 - accuracy: 0.9818 - val_loss: 0.7246 - val_accuracy: 0.8658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc82410280>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,steps_per_epoch=50000//16,\n",
    "epochs=3,\n",
    "validation_data=val_gen,validation_steps=2500//16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491710b8",
   "metadata": {},
   "source": [
    "## EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6875d3",
   "metadata": {},
   "source": [
    "## AT TRAINING TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49a479cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 988s 316ms/step - loss: 0.0275 - accuracy: 0.9908\n",
      "train accuracy 0.9907799959182739\n"
     ]
    }
   ],
   "source": [
    "tran_loss, train_acc = model.evaluate(train_gen)\n",
    "print(\"train accuracy\", train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32728f46",
   "metadata": {},
   "source": [
    "* WITH TRAIN DATA i HAVE GOT 99% ACCURACY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f6b04c",
   "metadata": {},
   "source": [
    "## AT TEST TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98872c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5705f5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(r\"C:\\Users\\HP\\Desktop\\xx\\test\", target_size=(200, 200), batch_size=16, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c35a9848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 140s 179ms/step - loss: 0.7216 - accuracy: 0.8645\n",
      "Test accuracy: 0.8644800186157227\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fddcfb",
   "metadata": {},
   "source": [
    "* WITH TEST DATA (UNSEEN DATA) I HAVE GOT 86% ACCURACY"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90f16924",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc24cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
